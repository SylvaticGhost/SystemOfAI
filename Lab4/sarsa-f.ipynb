{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up environment",
   "id": "6b495c78063e199e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.592617Z",
     "start_time": "2025-11-27T08:57:32.983951Z"
    }
   },
   "source": [
    "from ale_py import ALEInterface\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import numba\n",
    "import plotly.express as px"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment constants",
   "id": "d14f4ada62035ed4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.602131Z",
     "start_time": "2025-11-27T08:57:33.598587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FIRE_ACTIONS = [1, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "MOVE_ACTIONS = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "np.random.seed(42)"
   ],
   "id": "c8310881c0d32161",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.612138Z",
     "start_time": "2025-11-27T08:57:33.608140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "UP_DIRECTION = 0\n",
    "RIGHT_DIRECTION = 1\n",
    "LEFT_DIRECTION = 2\n",
    "DOWN_DIRECTION = 3\n",
    "UPRIGHT_DIRECTION = 4\n",
    "UPLEFT_DIRECTION = 5\n",
    "DOWNRIGHT_DIRECTION = 6\n",
    "DOWNLEFT_DIRECTION = 7\n",
    "\n",
    "ACTION_TO_DIRECTIONS = {\n",
    "    2: [0],  # UP\n",
    "    3: [1],  # RIGHT\n",
    "    4: [2],  # LEFT\n",
    "    5: [3],  # DOWN\n",
    "    6: [0, 1],  # UPRIGHT\n",
    "    7: [0, 2],  # UPLEFT\n",
    "    8: [3, 1],  # DOWNRIGHT\n",
    "    9: [3, 2],  # DOWNLEFT\n",
    "}"
   ],
   "id": "f1db9cfae656a91",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.622686Z",
     "start_time": "2025-11-27T08:57:33.618660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMPTY_COLOR = np.array([0, 0, 0], dtype=np.uint8)\n",
    "WALL_COLOR = np.array([84, 92, 214], dtype=np.uint8)\n",
    "ENEMY_COLOR = np.array([210, 210, 64], dtype=np.uint8)\n",
    "PLAYER_COLOR = np.array([240, 170, 103], dtype=np.uint8)\n",
    "\n",
    "EMPTY_INDEX = 0\n",
    "WALL_INDEX = 1\n",
    "ENEMY_INDEX = 2\n",
    "PLAYER_INDEX = 3\n",
    "\n",
    "PORTAL_INDEX = 4  # add manualy\n",
    "PORTAL_COLOR = np.array([74, 255, 56], dtype=np.uint8)\n",
    "\n",
    "AVG_PIXELS_IN_ENEMY = 74\n",
    "MAX_ENEMIES = 8"
   ],
   "id": "3b52870bd5f84e85",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## State processing functions",
   "id": "e8e2f06a3ff73d31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.657756Z",
     "start_time": "2025-11-27T08:57:33.628695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@numba.njit\n",
    "def rgb_to_index(frame):\n",
    "    state = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "    enemy_pixel_count = 0\n",
    "    for i in range(frame.shape[0]):\n",
    "        for j in range(frame.shape[1]):\n",
    "            pixel = frame[i, j]\n",
    "            if pixel[0] == WALL_COLOR[0]:\n",
    "                state[i, j] = WALL_INDEX\n",
    "            elif pixel[0] == ENEMY_COLOR[0]:\n",
    "                state[i, j] = ENEMY_INDEX\n",
    "                enemy_pixel_count += 1\n",
    "            elif pixel[0] == PLAYER_COLOR[0]:\n",
    "                state[i, j] = PLAYER_INDEX\n",
    "            elif pixel[0] == PORTAL_COLOR[0]:\n",
    "                state[i, j] = PORTAL_INDEX\n",
    "            else:\n",
    "                state[i, j] = EMPTY_INDEX\n",
    "    return state, enemy_pixel_count\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def cut_empty_layers(state):\n",
    "    skip_layers = 0\n",
    "    while True:\n",
    "        if state[skip_layers][skip_layers] == 0:\n",
    "            skip_layers += 1\n",
    "        else:\n",
    "            break\n",
    "    state = state[skip_layers:-skip_layers, skip_layers:-skip_layers]\n",
    "\n",
    "    skip_layers_from_bottom = 0\n",
    "    while True:\n",
    "        if state[-(skip_layers_from_bottom + 1)][-(skip_layers_from_bottom + 1)] == 0:\n",
    "            skip_layers_from_bottom += 1\n",
    "        else:\n",
    "            break\n",
    "    state = state[:-skip_layers_from_bottom, :]\n",
    "    return state\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def fill_part(matrix, a, b, c, d, fill_value):\n",
    "    rows, cols = matrix.shape\n",
    "    min_i = max(0, min(a[0], b[0], c[0], d[0]))\n",
    "    max_i = min(rows - 1, max(a[0], b[0], c[0], d[0]))\n",
    "    min_j = max(0, min(a[1], b[1], c[1], d[1]))\n",
    "    max_j = min(cols - 1, max(a[1], b[1], c[1], d[1]))\n",
    "\n",
    "    for ii in range(min_i, max_i + 1):\n",
    "        for jj in range(min_j, max_j + 1):\n",
    "            if matrix[ii, jj] == EMPTY_INDEX:\n",
    "                matrix[ii, jj] = fill_value\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def fill_holes(state):\n",
    "    PORTAL_MIN_LENGHT = 3\n",
    "    PORTAL_WIDTH = 0\n",
    "    WALL_WIDTH = 3\n",
    "\n",
    "    if state[0][0] != WALL_INDEX:\n",
    "        return\n",
    "\n",
    "    P = 2 * (state.shape[0] + state.shape[1])\n",
    "\n",
    "    i, j = 0, 0\n",
    "    height, width = state.shape\n",
    "    last_wall_pixel = (0, 0)\n",
    "    iters = 0\n",
    "    while True:\n",
    "        if iters > P + 1:\n",
    "            raise Warning(\"No walls found on border during hole filling\")\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "        if state[i][j] == WALL_INDEX:\n",
    "            distance_to_last_wall = max(abs(i - last_wall_pixel[0]), abs(j - last_wall_pixel[1]))\n",
    "            if distance_to_last_wall == 1:\n",
    "                pass\n",
    "            else:\n",
    "                material_to_fill = WALL_INDEX if distance_to_last_wall < PORTAL_MIN_LENGHT else PORTAL_INDEX\n",
    "                width_to_fill = WALL_WIDTH if material_to_fill == WALL_INDEX else PORTAL_WIDTH\n",
    "                A, B, C, D = None, None, None, None\n",
    "                if j == 0:\n",
    "                    A = (last_wall_pixel[0] + 1, last_wall_pixel[1])\n",
    "                    B = (last_wall_pixel[0] + 1, last_wall_pixel[1] + width_to_fill)\n",
    "                    C = (i, j + width_to_fill)\n",
    "                    D = (i, j)\n",
    "                elif i == height - 1:\n",
    "                    A = (last_wall_pixel[0], last_wall_pixel[1] + 1)\n",
    "                    B = (last_wall_pixel[0] - width_to_fill, last_wall_pixel[1] + 1)\n",
    "                    C = (i - width_to_fill, j)\n",
    "                    D = (i, j)\n",
    "                elif j == width - 1:\n",
    "                    A = (last_wall_pixel[0] - 1, last_wall_pixel[1])\n",
    "                    B = (last_wall_pixel[0] - 1, last_wall_pixel[1] - width_to_fill)\n",
    "                    C = (i, j - width_to_fill)\n",
    "                    D = (i, j)\n",
    "                elif i == 0:\n",
    "                    A = (last_wall_pixel[0], last_wall_pixel[1] - 1)\n",
    "                    B = (last_wall_pixel[0] - width_to_fill, last_wall_pixel[1] - 1)\n",
    "                    C = (i + width_to_fill, j)\n",
    "                    D = (i, j)\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected wall pixel not on border\")\n",
    "\n",
    "                fill_part(state, A, B, C, D, material_to_fill)\n",
    "\n",
    "            last_wall_pixel = (i, j)\n",
    "\n",
    "        if j == 0 and i < height - 1:\n",
    "            i += 1\n",
    "        elif i == height - 1 and j < width - 1:\n",
    "            j += 1\n",
    "        elif j == width - 1 and i > 0:\n",
    "            i -= 1\n",
    "        elif i == 0 and j > 0:\n",
    "            j -= 1\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            break\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def find_player_box(state):\n",
    "    player_positions = np.argwhere(state == PLAYER_INDEX)\n",
    "\n",
    "    if player_positions.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    i_pos = player_positions[:, 0]\n",
    "    j_pos = player_positions[:, 1]\n",
    "    box = (np.min(i_pos), np.min(j_pos), np.max(i_pos), np.max(j_pos))\n",
    "    return box\n",
    "\n",
    "@numba.njit\n",
    "def _int_linspace(start, stop, count):\n",
    "    arr = np.empty(count, dtype=np.int32)\n",
    "    if count == 1:\n",
    "        arr[0] = start\n",
    "        return arr\n",
    "    step = (stop - start) / (count - 1)\n",
    "    for k in range(count):\n",
    "        arr[k] = int(start + k * step)\n",
    "    return arr\n",
    "\n",
    "@numba.njit\n",
    "def get_scanning_points(box):\n",
    "    \"\"\"\n",
    "    :return: left_search_points, right_search_points, up_search_points, down_search_points\n",
    "    \"\"\"\n",
    "    vertical_aligments_search_points_y = _int_linspace(box[0], box[2], 4)\n",
    "    left_search_points = [(y, box[1]) for y in vertical_aligments_search_points_y]\n",
    "    right_search_points = [(y, box[3]) for y in vertical_aligments_search_points_y]\n",
    "\n",
    "    horizontal_search_points_x = _int_linspace(box[1], box[3], 2)\n",
    "    up_search_points = [(box[0], x) for x in horizontal_search_points_x]\n",
    "    down_search_points = [(box[2], x) for x in horizontal_search_points_x]\n",
    "\n",
    "    return left_search_points, right_search_points, up_search_points, down_search_points\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def basic_observation(state, box):\n",
    "    if box is None:\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    left_search_points, right_search_points, up_search_points, down_search_points = get_scanning_points(box)\n",
    "\n",
    "    l_wall = (left_search_points[0][0], 0)\n",
    "    r_wall = (right_search_points[0][0], state.shape[1] - 1)\n",
    "    u_wall = (0, up_search_points[0][1])\n",
    "    d_wall = (state.shape[0] - 1, down_search_points[0][1])\n",
    "\n",
    "    reach_l, reach_r, reach_u, reach_d = False, False, False, False\n",
    "\n",
    "    closest_enemy = None\n",
    "    closest_portal = None\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i > max(state.shape):\n",
    "            raise ValueError(\"No walls found in any direction\")\n",
    "\n",
    "        if not reach_l:\n",
    "            cords = [(point[0], point[1] - i) for point in left_search_points]\n",
    "            for cord in cords:\n",
    "                material = state[cord]\n",
    "                if material == WALL_INDEX or cords[0][1] == 0:\n",
    "                    reach_l = True\n",
    "                    l_wall = cord\n",
    "                if material == PORTAL_INDEX:\n",
    "                    reach_l = True\n",
    "                    if closest_portal is None:\n",
    "                        closest_portal = cord\n",
    "                elif material == ENEMY_INDEX:\n",
    "                    if closest_enemy is None:\n",
    "                        closest_enemy = cord\n",
    "\n",
    "                if reach_l:\n",
    "                    break\n",
    "\n",
    "        if not reach_r:\n",
    "            cords = [(point[0], point[1] + i) for point in right_search_points]\n",
    "            for cord in cords:\n",
    "                material = state[cord]\n",
    "                if material == WALL_INDEX or cord[1] == state.shape[1] - 1:\n",
    "                    reach_r = True\n",
    "                    r_wall = cord\n",
    "                elif material == PORTAL_INDEX:\n",
    "                    reach_r = True\n",
    "                    if closest_portal is None:\n",
    "                        closest_portal = cord\n",
    "                elif material == ENEMY_INDEX:\n",
    "                    if closest_enemy is None:\n",
    "                        closest_enemy = cord\n",
    "\n",
    "                if reach_r:\n",
    "                    break\n",
    "\n",
    "        if not reach_u:\n",
    "            cords = [(point[0] - i, point[1]) for point in up_search_points]\n",
    "            for cord in cords:\n",
    "                material = state[cord]\n",
    "                if material == WALL_INDEX or cord[0] == 0:\n",
    "                    reach_u = True\n",
    "                    u_wall = cord\n",
    "                elif material == PORTAL_INDEX:\n",
    "                    reach_u = True\n",
    "                    if closest_portal is None:\n",
    "                        closest_portal = cord\n",
    "                elif material == ENEMY_INDEX:\n",
    "                    if closest_enemy is None:\n",
    "                        closest_enemy = cord\n",
    "\n",
    "                if reach_u:\n",
    "                    break\n",
    "\n",
    "        if not reach_d:\n",
    "            cords = [(point[0] + i, point[1]) for point in down_search_points]\n",
    "            for cord in cords:\n",
    "                material = state[cord]\n",
    "                if material == WALL_INDEX or cord[0] == state.shape[0] - 1:\n",
    "                    reach_d = True\n",
    "                    d_wall = cord\n",
    "                if material == PORTAL_INDEX:\n",
    "                    reach_d = True\n",
    "                    if closest_portal is None:\n",
    "                        closest_portal = cord\n",
    "                elif material == ENEMY_INDEX:\n",
    "                    if closest_enemy is None:\n",
    "                        closest_enemy = cord\n",
    "\n",
    "                if reach_d:\n",
    "                    break\n",
    "\n",
    "        if reach_l and reach_r and reach_u and reach_d:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    return l_wall, r_wall, u_wall, d_wall, closest_enemy, closest_portal"
   ],
   "id": "5aa432d125afccc7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.668172Z",
     "start_time": "2025-11-27T08:57:33.663135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@numba.njit\n",
    "def cut_empty_layers_in_frame(frame):\n",
    "    skip_layers = 0\n",
    "    while True:\n",
    "        if np.array_equal(frame[skip_layers][skip_layers], EMPTY_COLOR):\n",
    "            skip_layers += 1\n",
    "        else:\n",
    "            break\n",
    "    frame = frame[skip_layers:-skip_layers, skip_layers:-skip_layers]\n",
    "\n",
    "    skip_layers_from_bottom = 0\n",
    "    while True:\n",
    "        if np.array_equal(frame[-(skip_layers_from_bottom + 1)][-(skip_layers_from_bottom + 1)], EMPTY_COLOR):\n",
    "            skip_layers_from_bottom += 1\n",
    "        else:\n",
    "            break\n",
    "    frame = frame[:-skip_layers_from_bottom, :]\n",
    "    return frame\n"
   ],
   "id": "45f5c0abc04aa454",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## State representation class",
   "id": "87fee8a17dc37ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.692210Z",
     "start_time": "2025-11-27T08:57:33.675696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VECTOR_STATE_SIZE = 16\n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, frame):\n",
    "        frame = cut_empty_layers_in_frame(frame)\n",
    "        state, enemy_pixels = rgb_to_index(frame)\n",
    "        self.is_empty = len(state) == 0 or len(state[0]) == 0\n",
    "        if not self.is_empty:\n",
    "            fill_holes(state)\n",
    "            self.state = state\n",
    "            self.state_h = state.shape[0]\n",
    "            self.state_w = state.shape[1]\n",
    "            self.player_box = find_player_box(state)\n",
    "            obs = basic_observation(state, self.player_box) if not self.player_box is None else None\n",
    "\n",
    "            self.left_wall = obs[0] if obs is not None and obs[0] is not None else (0, 0)\n",
    "            self.right_wall = obs[1] if obs is not None and obs[1] is not None else (0, 0)\n",
    "            self.up_wall = obs[2] if obs is not None and obs[2] is not None else (0, 0)\n",
    "            self.down_wall = obs[3] if obs is not None and obs[3] is not None else (0, 0)\n",
    "            self.closest_enemy = obs[4] if obs is not None and obs[4] is not None else None\n",
    "            self.closest_portal = obs[5] if obs is not None and obs[5] is not None else None\n",
    "            self.enemies = np.round(float(enemy_pixels) / AVG_PIXELS_IN_ENEMY).astype(np.int32)\n",
    "\n",
    "            self.area = self.state_h * self.state_w\n",
    "        else:\n",
    "            self.player_box = None\n",
    "            self.area = 0\n",
    "\n",
    "    def has_enemy(self):\n",
    "        return self.enemies > 0 or self.closest_enemy is not None\n",
    "\n",
    "    def percentage_from_area(self, pixels):\n",
    "        if self.is_empty or self.area == 0:\n",
    "            return 0.0\n",
    "        return pixels / self.area\n",
    "\n",
    "    def get_direction_on_closest_wall(self):\n",
    "        center_of_player = self.center_of_player()\n",
    "        up_dist = center_of_player[0] - self.up_wall[0]\n",
    "        down_dist = self.down_wall[0] - center_of_player[0]\n",
    "        left_dist = center_of_player[1] - self.left_wall[1]\n",
    "        right_dist = self.right_wall[1] - center_of_player[1]\n",
    "\n",
    "        dists = [up_dist, right_dist, left_dist, down_dist]\n",
    "        min_dist = min(dists)\n",
    "        return dists.index(min_dist)\n",
    "\n",
    "    def get_distance_to_closest_wall(self):\n",
    "        center_of_player = self.center_of_player()\n",
    "        up_dist = center_of_player[0] - self.up_wall[0]\n",
    "        down_dist = self.down_wall[0] - center_of_player[0]\n",
    "        left_dist = center_of_player[1] - self.left_wall[1]\n",
    "        right_dist = self.right_wall[1] - center_of_player[1]\n",
    "\n",
    "        dists = [up_dist, right_dist, left_dist, down_dist]\n",
    "        min_dist = min(dists)\n",
    "        return min_dist\n",
    "\n",
    "    def as_vector(self):\n",
    "        player_center = self.center_of_player()\n",
    "        px_norm = player_center[0] / self.state_h\n",
    "        py_norm = player_center[1] / self.state_w\n",
    "\n",
    "        up_wall_dist = player_center[0] - self.up_wall[0]\n",
    "        down_wall_dist = self.down_wall[0] - player_center[0]\n",
    "        left_wall_dist = player_center[1] - self.left_wall[1]\n",
    "        right_wall_dist = self.right_wall[1] - player_center[1]\n",
    "\n",
    "        dist_up_norm = up_wall_dist / self.state_h\n",
    "        dist_down_norm = down_wall_dist / self.state_h\n",
    "        dist_left_norm = left_wall_dist / self.state_w\n",
    "        dist_right_norm = right_wall_dist / self.state_w\n",
    "\n",
    "        epsilon = 1e-3\n",
    "        inv_up = 1.0 / (dist_up_norm + epsilon)\n",
    "        inv_down = 1.0 / (dist_down_norm + epsilon)\n",
    "        inv_left = 1.0 / (dist_left_norm + epsilon)\n",
    "        inv_right = 1.0 / (dist_right_norm + epsilon)\n",
    "\n",
    "        enemy_x_norm = self.closest_enemy[0] / self.state_h if self.closest_enemy is not None else 0\n",
    "        enemy_y_norm = self.closest_enemy[1] / self.state_w if self.closest_enemy is not None else 0\n",
    "        enemy_visible = 1.0 if self.closest_enemy is not None else 0.0\n",
    "\n",
    "        enemy_count = self.enemies / MAX_ENEMIES\n",
    "        portal_x_norm = self.closest_portal[0] / self.state_h if self.closest_portal is not None else 0\n",
    "        portal_y_norm = self.closest_portal[1] / self.state_w if self.closest_portal is not None else 0\n",
    "\n",
    "        return np.array([px_norm, py_norm,\n",
    "                         dist_up_norm, dist_down_norm,\n",
    "                         dist_left_norm, dist_right_norm,\n",
    "                         inv_up, inv_down,\n",
    "                         inv_left, inv_right,\n",
    "                         enemy_x_norm, enemy_y_norm,\n",
    "                         enemy_visible, enemy_count, portal_x_norm, portal_y_norm], dtype=np.float32)\n",
    "\n",
    "    def center_of_player(self):\n",
    "        if self.player_box is None:\n",
    "            return 0, 0\n",
    "        i_center = (self.player_box[0] + self.player_box[2]) // 2\n",
    "        j_center = (self.player_box[1] + self.player_box[3]) // 2\n",
    "        return i_center, j_center\n",
    "\n",
    "    def distance_from_player(self, cord, failure_val=-1):\n",
    "        if self.is_empty or self.player_box is None:\n",
    "            return failure_val\n",
    "\n",
    "        player_x, player_y = self.center_of_player()\n",
    "        return np.sqrt((player_x - cord[0]) ** 2 + (player_y - cord[1]) ** 2)\n",
    "\n",
    "    def distance_to_closest_border(self):\n",
    "        player_x, player_y = self.center_of_player()\n",
    "        up_dist = player_x - self.up_wall[0]\n",
    "        down_dist = self.down_wall[0] - player_x\n",
    "        left_dist = player_y - self.left_wall[1]\n",
    "        right_dist = self.right_wall[1] - player_y\n",
    "        return min(up_dist, down_dist, left_dist, right_dist)\n",
    "\n",
    "    def direction_to_player(self, cord):\n",
    "        i, j = cord\n",
    "        left_up_corner = (self.player_box[0], self.player_box[1])\n",
    "        left_down_corner = (self.player_box[2], self.player_box[1])\n",
    "        right_up_corner = (self.player_box[0], self.player_box[3])\n",
    "        right_down_corner = (self.player_box[2], self.player_box[3])\n",
    "\n",
    "        if i < left_up_corner[0]:\n",
    "            if j < left_up_corner[1]:\n",
    "                return UPLEFT_DIRECTION\n",
    "            elif j > right_up_corner[1]:\n",
    "                return UPRIGHT_DIRECTION\n",
    "            else:\n",
    "                return UP_DIRECTION\n",
    "        elif i > left_down_corner[0]:\n",
    "            if j < left_down_corner[1]:\n",
    "                return DOWNLEFT_DIRECTION\n",
    "            elif j > right_down_corner[1]:\n",
    "                return DOWNRIGHT_DIRECTION\n",
    "            else:\n",
    "                return DOWN_DIRECTION\n",
    "        else:\n",
    "            if j < left_up_corner[1]:\n",
    "                return LEFT_DIRECTION\n",
    "            elif j > right_up_corner[1]:\n",
    "                return RIGHT_DIRECTION\n",
    "            else:\n",
    "                return -1\n"
   ],
   "id": "64756db9b5892c5c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.711125Z",
     "start_time": "2025-11-27T08:57:33.698721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@numba.njit\n",
    "def mark_scanned_line(mask, r0, c0, r1, c1):\n",
    "    \"\"\"\n",
    "    Marks pixels along a scan ray as 'seen'.\n",
    "    Returns number of newly seen pixels.\n",
    "    \"\"\"\n",
    "    new_pixels = 0\n",
    "    if r0 == r1: # Horizontal line\n",
    "        c_start = min(c0, c1)\n",
    "        c_end = max(c0, c1)\n",
    "        for c in range(c_start, c_end + 1):\n",
    "             if 0 <= r0 < mask.shape[0] and 0 <= c < mask.shape[1]:\n",
    "                if mask[r0, c] == 0:\n",
    "                    mask[r0, c] = 2 # 2 = Scanned/Seen\n",
    "                    new_pixels += 1\n",
    "    elif c0 == c1: # Vertical line\n",
    "        r_start = min(r0, r1)\n",
    "        r_end = max(r0, r1)\n",
    "        for r in range(r_start, r_end + 1):\n",
    "            if 0 <= r < mask.shape[0] and 0 <= c0 < mask.shape[1]:\n",
    "                if mask[r, c0] == 0:\n",
    "                    mask[r, c0] = 2\n",
    "                    new_pixels += 1\n",
    "    return new_pixels\n",
    "\n",
    "@numba.njit\n",
    "def mark_scanned_traces_from_box(mask, box, up_wall, down_wall, left_wall, right_wall):\n",
    "    \"\"\"\n",
    "    Marks the scan lines from the player box to the walls.\n",
    "    Returns number of newly seen pixels.\n",
    "    \"\"\"\n",
    "    left_points, right_points, up_points, down_points = get_scanning_points(box)\n",
    "    new_pixels = 0\n",
    "\n",
    "    for point in left_points:\n",
    "        new_pixels += mark_scanned_line(mask, point[0], point[1], left_wall[0], left_wall[1])\n",
    "    for point in right_points:\n",
    "        new_pixels += mark_scanned_line(mask, point[0], point[1], right_wall[0], right_wall[1])\n",
    "    for point in up_points:\n",
    "        new_pixels += mark_scanned_line(mask, point[0], point[1], up_wall[0], up_wall[1])\n",
    "    for point in down_points:\n",
    "        new_pixels += mark_scanned_line(mask, point[0], point[1], down_wall[0], down_wall[1])\n",
    "\n",
    "    return new_pixels\n",
    "\n",
    "@numba.njit\n",
    "def mark_pixels_in_box(mask, r_min, c_min, r_max, c_max):\n",
    "    \"\"\"\n",
    "    Marks the rectangular area covered by the player.\n",
    "    Returns the number of *newly* visited pixels.\n",
    "    \"\"\"\n",
    "    r_min = max(0, min(r_min, mask.shape[0]))\n",
    "    c_min = max(0, min(c_min, mask.shape[1]))\n",
    "    r_max = max(0, min(r_max, mask.shape[0]))\n",
    "    c_max = max(0, min(c_max, mask.shape[1]))\n",
    "\n",
    "    new_pixels = 0\n",
    "    for r in range(r_min, r_max):\n",
    "        for c in range(c_min, c_max):\n",
    "            if mask[r, c] == 0:\n",
    "                mask[r, c] = 1 # 1 = Visited by Player Body\n",
    "                new_pixels += 1\n",
    "    return new_pixels\n",
    "\n",
    "class ExplorationTracker:\n",
    "    def __init__(self, h, w):\n",
    "        self.height = h\n",
    "        self.width = w\n",
    "        self.space = np.zeros((w, h), dtype=np.int32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.space = np.zeros((self.width, self.height), dtype=np.int32)\n",
    "\n",
    "    def cover(self, state: State):\n",
    "        \"\"\"\n",
    "        :return: new visited pixels, new scanned pixels\n",
    "        \"\"\"\n",
    "\n",
    "        if state.player_box is None:\n",
    "            return 0, 0\n",
    "\n",
    "        r_min, c_min, r_max, c_max = state.player_box\n",
    "        new_visited = mark_pixels_in_box(self.space, r_min, c_min, r_max, c_max)\n",
    "\n",
    "        new_scanned = mark_scanned_traces_from_box(self.space, state.player_box, state.up_wall, state.down_wall, state.left_wall, state.right_wall)\n",
    "\n",
    "        return new_visited, new_scanned"
   ],
   "id": "648eda23c445fa18",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "b1fcf0fa054e516f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SARSA agent class",
   "id": "c9cf04bfa2dc761c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.726733Z",
     "start_time": "2025-11-27T08:57:33.717214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sarsa:\n",
    "    alpha = 1e-5\n",
    "    gamma = 0.99\n",
    "    epsilon = 1\n",
    "    lmbda = 0.9\n",
    "    weight_decay = 1e-5\n",
    "    z_clip = 10.0\n",
    "\n",
    "    def __init__(self, n_actions):\n",
    "        self.state_dim = VECTOR_STATE_SIZE\n",
    "        self.n_actions = n_actions\n",
    "        self.w = np.zeros((self.n_actions, self.state_dim), dtype=np.float32)\n",
    "        self.b = np.zeros(self.n_actions, dtype=np.float32)\n",
    "        self.z_w = np.zeros_like(self.w, dtype=np.float32)\n",
    "        self.z_b = np.zeros((self.n_actions,), dtype=np.float32)\n",
    "\n",
    "    def phi_from_state_action(self, features, action):\n",
    "        phi_w = np.zeros_like(self.w, dtype=np.float32)\n",
    "        phi_w[action] = features.astype(np.float32)\n",
    "        phi_b = np.zeros_like(self.b, dtype=np.float32)\n",
    "        phi_b[action] = 1.0\n",
    "        return phi_w, phi_b\n",
    "\n",
    "    def _q_values_all_actions(self, state_features):\n",
    "        return self.w.dot(state_features.astype(np.float32)) + self.b\n",
    "\n",
    "    def epsilon_greedy(self, features):\n",
    "        eps = float(getattr(self, \"epsilon\", 0.0))\n",
    "        eps = max(0.0, min(1.0, eps))\n",
    "\n",
    "        q_vals = self._q_values_all_actions(features)\n",
    "\n",
    "        if np.random.rand() < eps:\n",
    "            action = np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            action = np.argmax(q_vals)\n",
    "\n",
    "        return action, q_vals\n",
    "\n",
    "    def save(self, file_name=\"sarsa_weights.npz\"):\n",
    "        np.savez(file_name, w=self.w.reshape(-1), b=self.b, n_actions=self.n_actions, state_dim=self.state_dim)\n",
    "\n",
    "    def restrict_exploration(self):\n",
    "        self.epsilon = 0.0\n",
    "\n",
    "    def reset_traces(self):\n",
    "        self.z_w.fill(0.0)\n",
    "        self.z_b.fill(0.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(file_name=\"sarsa_weights.npz\"):\n",
    "        data = np.load(file_name)\n",
    "        n_actions = int(data['n_actions'])\n",
    "        state_dim = int(data['state_dim'])\n",
    "        agent = Sarsa(n_actions)\n",
    "        agent.state_dim = state_dim\n",
    "        agent.w = data['w'].reshape((n_actions, state_dim)).astype(np.float32)\n",
    "        agent.b = data['b'].astype(np.float32) if 'b' in data else np.zeros(n_actions, dtype=np.float32)\n",
    "        agent.z_w = np.zeros_like(agent.w, dtype=np.float32)\n",
    "        agent.z_b = np.zeros_like(agent.b, dtype=np.float32)\n",
    "        return agent"
   ],
   "id": "2fe5226f26d9d624",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.737638Z",
     "start_time": "2025-11-27T08:57:33.733638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def file_exist(file_name):\n",
    "    try:\n",
    "        _ = np.load(file_name)\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        return False"
   ],
   "id": "eac21ca3fc3518d3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Examinator class for reward shaping",
   "id": "3ad33483c3f2c9ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.753266Z",
     "start_time": "2025-11-27T08:57:33.743250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Examinator:\n",
    "    ENV_REWARD_DESCALE = 20\n",
    "\n",
    "    NOT_SHOOT_ENEMY_PENALTY = -1.3051  # reduced from -1.5\n",
    "    LIVING_PENALTY = -0.016801  # reduced from -0.1\n",
    "    DEATH_PENALTY = -25  # increased from -12\n",
    "    STAY_IN_DANGER_PENALTY = -0.4  # reduced from -0.5\n",
    "    FIRE_ENEMY_BONUS = 1.2  # reduced from 6.0 (or set to 0.0)\n",
    "    FAR_FROM_WALL_BONUS = 0.15  # reduced from 0.03\n",
    "    MOVE_BONUS = 0.015\n",
    "    BONUS_FOR_NOT_SHOOT_NOWHERE = 0.62\n",
    "    GO_TO_WALL_PENALTY = -0.15\n",
    "    SHOOT_WHEN_NO_ENEMIES_PENALTY = -0.3\n",
    "    STABLE_BONUS_ON_CLEARED_LEVEL = 0.05\n",
    "    BONUS_FOR_SCANNED_PIXEL = 0.0002\n",
    "    BONUS_FOR_VISITED_PIXEL = 0.005\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def examine(self, state, action, model, reward, prev_state, scanned_pixels=0, visited_pixels=0):\n",
    "        shaped_reward = reward / Examinator.ENV_REWARD_DESCALE\n",
    "\n",
    "        shaped_reward += self.LIVING_PENALTY\n",
    "\n",
    "        if state.closest_enemy is not None:\n",
    "            enemy_dir = state.direction_to_player(state.closest_enemy)\n",
    "            required_action = FIRE_ACTIONS[1] + enemy_dir\n",
    "            if action != required_action and reward <= 0:\n",
    "                shaped_reward += Examinator.NOT_SHOOT_ENEMY_PENALTY\n",
    "            if action == 0:\n",
    "                shaped_reward += Examinator.STAY_IN_DANGER_PENALTY\n",
    "            if action == required_action:\n",
    "                shaped_reward += Examinator.FIRE_ENEMY_BONUS\n",
    "        else:\n",
    "            if action not in FIRE_ACTIONS and action != 0:\n",
    "                shaped_reward += Examinator.BONUS_FOR_NOT_SHOOT_NOWHERE\n",
    "\n",
    "        alive = state.player_box is not None\n",
    "        if not alive:\n",
    "            shaped_reward += Examinator.DEATH_PENALTY\n",
    "\n",
    "        min_distance_to_wall = min(\n",
    "            state.center_of_player()[0] - state.up_wall[0],\n",
    "            state.down_wall[0] - state.center_of_player()[0],\n",
    "            state.center_of_player()[1] - state.left_wall[1],\n",
    "            state.right_wall[1] - state.center_of_player()[1]\n",
    "        )\n",
    "        if min_distance_to_wall > 15:\n",
    "            shaped_reward += Examinator.FAR_FROM_WALL_BONUS\n",
    "\n",
    "        if action in MOVE_ACTIONS:\n",
    "            shaped_reward += Examinator.BONUS_FOR_SCANNED_PIXEL * scanned_pixels\n",
    "            shaped_reward += Examinator.BONUS_FOR_VISITED_PIXEL * visited_pixels\n",
    "\n",
    "            dir_to_closest_wall = state.get_direction_on_closest_wall()\n",
    "            action_components = ACTION_TO_DIRECTIONS.get(action, [])\n",
    "\n",
    "            if dir_to_closest_wall in action_components:\n",
    "                # Calculate how dangerous this move is based on distance\n",
    "                dist_to_wall = state.distance_to_closest_border()\n",
    "\n",
    "                # If very close (e.g., < 15 pixels), apply heavy penalty\n",
    "                if dist_to_wall < 15:\n",
    "                    # The closer we are, the higher the penalty.\n",
    "                    # Example: at 1px dist, penalty is -1.0. At 15px, it is -0.06\n",
    "                    proximity_penalty = -1.0 * (15.0 / (dist_to_wall + 1.0))\n",
    "                    shaped_reward += proximity_penalty\n",
    "                else:\n",
    "                    shaped_reward += Examinator.GO_TO_WALL_PENALTY  # Standard small penalty\n",
    "\n",
    "        if state.enemies == 0:\n",
    "            if not alive:\n",
    "                shaped_reward += Examinator.DEATH_PENALTY\n",
    "                return shaped_reward\n",
    "            else:\n",
    "                shaped_reward += Examinator.STABLE_BONUS_ON_CLEARED_LEVEL\n",
    "\n",
    "            if action in FIRE_ACTIONS:\n",
    "                shaped_reward += Examinator.SHOOT_WHEN_NO_ENEMIES_PENALTY\n",
    "\n",
    "            # rewarding to be near walls when no enemies to find portals\n",
    "            distance_to_closest_wall = state.distance_to_closest_border()\n",
    "            if 15 < distance_to_closest_wall < 30:\n",
    "                shaped_reward += 0.15\n",
    "            elif 30 <= distance_to_closest_wall < 40:\n",
    "                shaped_reward += 0.07\n",
    "\n",
    "            if state.closest_portal is not None:\n",
    "                #bonus for finding portal\n",
    "                if prev_state.closest_portal is None:\n",
    "                    shaped_reward += 15.0\n",
    "                else:\n",
    "                    prev_distance = prev_state.distance_from_player(prev_state.closest_portal)\n",
    "                    curr_distance = state.distance_from_player(state.closest_portal)\n",
    "                    if curr_distance < prev_distance:\n",
    "                        shaped_reward += 1\n",
    "\n",
    "            if state.closest_portal is None and prev_state.closest_portal is not None:\n",
    "                #penalty for losing portal\n",
    "                shaped_reward += -5.0\n",
    "\n",
    "        return shaped_reward\n"
   ],
   "id": "e551160f85718ea2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.764194Z",
     "start_time": "2025-11-27T08:57:33.759274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LastActionTracker:\n",
    "    def __init__(self, space_size):\n",
    "        self.space_size = space_size\n",
    "        self.actions = []\n",
    "\n",
    "    def rec(self, action):\n",
    "        self.actions.append(action)\n",
    "        if len(self.actions) > self.space_size:\n",
    "            self.actions.pop(0)\n",
    "\n",
    "    def last_same_count(self):\n",
    "        if not self.actions:\n",
    "            return 0\n",
    "        last_action = self.actions[-1]\n",
    "        count = 0\n",
    "        for action in reversed(self.actions):\n",
    "            if action == last_action:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        return count"
   ],
   "id": "c5ea0e00870b528b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trainer class",
   "id": "b2f5f161e09f5dff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.791768Z",
     "start_time": "2025-11-27T08:57:33.772231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Trainer:\n",
    "    def __init__(self, epsilon_min=0.05, epsilon_decay_fraction=0.999, initial_epsilon=1.0):\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay_fraction = epsilon_decay_fraction\n",
    "        self.initial_epsilon = initial_epsilon\n",
    "\n",
    "    @staticmethod\n",
    "    def _file_name_for_class(class_name):\n",
    "        return f\"sarsa-weights-{class_name.lower()}.npz\"\n",
    "\n",
    "    def train_if_needed(self, model, env, class_name, n_episodes=1000):\n",
    "        file_name = Trainer._file_name_for_class(class_name)\n",
    "        print(f'Checking for existing model file: {file_name}')\n",
    "        if not file_exist(file_name):\n",
    "            self.train(model, env, class_name, n_episodes)\n",
    "            return model\n",
    "\n",
    "        return Sarsa.load(file_name)\n",
    "\n",
    "    def train(self, model, env, class_name, n_episodes=1000):\n",
    "        print(f\"Training {class_name} agent...\")\n",
    "        action_counts = np.zeros(env.action_space.n, dtype=np.float32)\n",
    "\n",
    "        examinator = Examinator()\n",
    "\n",
    "        rewards = []\n",
    "        w_changes = []\n",
    "        previous_w = model.w.copy()\n",
    "\n",
    "        model.epsilon = self.initial_epsilon\n",
    "        decay_episodes = int(n_episodes * self.epsilon_decay_fraction)\n",
    "        if decay_episodes > 0:\n",
    "            epsilon_decay_step = (self.initial_epsilon - self.epsilon_min) / decay_episodes\n",
    "        else:\n",
    "            epsilon_decay_step = 0\n",
    "        print(f\"Epsilon will decay from {self.initial_epsilon} to {self.epsilon_min} over {decay_episodes} episodes.\")\n",
    "\n",
    "        log_step = max(1, n_episodes // 100)\n",
    "        action_duplicate_tolerance = 8\n",
    "\n",
    "        scanned_pixels_by_episode_percentage = []\n",
    "        visited_pixels_by_episode_percentage = []\n",
    "\n",
    "        for episode in range(n_episodes):\n",
    "            _ = env.reset()\n",
    "\n",
    "            for j in range(0, 6):  # skip initial no-op frames\n",
    "                _ = env.step(0)\n",
    "\n",
    "            last_action_tracker = LastActionTracker(space_size=action_duplicate_tolerance)\n",
    "            exploration_tracker = ExplorationTracker(160, 210)\n",
    "\n",
    "            state = env.render()\n",
    "            featured_state = State(state)\n",
    "            state_vector = featured_state.as_vector()\n",
    "            distance_to_closest_enemy = featured_state.distance_from_player(\n",
    "                featured_state.closest_enemy) if featured_state.closest_enemy is not None else -1\n",
    "            model.reset_traces()\n",
    "\n",
    "            action, q_values = model.epsilon_greedy(state_vector)\n",
    "            action_counts[action] += 1\n",
    "\n",
    "            done = False\n",
    "            ep_reward = 0\n",
    "\n",
    "            visited_pixels_percantages = []\n",
    "            scanned_pixels_percantages = []\n",
    "\n",
    "            while not done:\n",
    "                next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "                next_featured_state = State(next_state)\n",
    "\n",
    "                #end episode if no player box (death) or empty state\n",
    "                if next_featured_state.is_empty:\n",
    "                    done = True\n",
    "                    shaped_reward = reward + Examinator.DEATH_PENALTY\n",
    "                    q_next = 0.0\n",
    "                    next_action = None\n",
    "                else:\n",
    "                    done = terminated or truncated or next_featured_state.player_box is None\n",
    "                    next_features = next_featured_state.as_vector()\n",
    "                    next_action, next_q_values = model.epsilon_greedy(next_features)\n",
    "\n",
    "                    visited_pixels, scanned_pixels = exploration_tracker.cover(next_featured_state)\n",
    "\n",
    "                    visited_percentage = next_featured_state.percentage_from_area(visited_pixels)\n",
    "                    scanned_percentage = next_featured_state.percentage_from_area(scanned_pixels)\n",
    "                    visited_pixels_percantages.append(visited_percentage)\n",
    "                    scanned_pixels_percantages.append(scanned_percentage)\n",
    "\n",
    "                    shaped_reward = examinator.examine(next_featured_state, action, model, reward, featured_state, scanned_pixels, visited_pixels)\n",
    "\n",
    "                    if last_action_tracker.last_same_count() >= action_duplicate_tolerance and action == next_action:\n",
    "                        shaped_reward += -0.2\n",
    "\n",
    "                    new_distance_to_closest_enemy = next_featured_state.distance_from_player(\n",
    "                        next_featured_state.closest_enemy) if next_featured_state.closest_enemy is not None else -1\n",
    "\n",
    "                    if new_distance_to_closest_enemy != -1 and distance_to_closest_enemy != -1 and distance_to_closest_enemy - new_distance_to_closest_enemy > 0 and new_distance_to_closest_enemy < 20:\n",
    "                        shaped_reward += -0.02\n",
    "                    distance_to_closest_enemy = new_distance_to_closest_enemy\n",
    "\n",
    "                    q_next = 0.0 if done else next_q_values[next_action]\n",
    "\n",
    "                q = q_values[action]\n",
    "                delta = shaped_reward + model.gamma * q_next - q\n",
    "\n",
    "                phi_w, phi_b = model.phi_from_state_action(state_vector, action)\n",
    "\n",
    "                model.z_w = (model.gamma * model.lmbda * model.z_w) + phi_w\n",
    "                model.z_b = (model.gamma * model.lmbda * model.z_b) + phi_b\n",
    "\n",
    "                model.w += model.alpha * delta * model.z_w\n",
    "                model.b += model.alpha * delta * model.z_b\n",
    "\n",
    "                model.w *= (1.0 - model.weight_decay)\n",
    "                model.b *= (1.0 - model.weight_decay)\n",
    "\n",
    "                model.z_w = np.clip(model.z_w, -model.z_clip, model.z_clip)\n",
    "                model.z_b = np.clip(model.z_b, -model.z_clip, model.z_clip)\n",
    "\n",
    "                if not done:\n",
    "                    featured_state = next_featured_state\n",
    "                    state_vector = next_features\n",
    "                    action = next_action\n",
    "                    q_values = next_q_values\n",
    "                    action_counts[action] += 1\n",
    "                    last_action_tracker.rec(action)\n",
    "\n",
    "                ep_reward += reward\n",
    "\n",
    "            scanned_pixels_by_episode_percentage.append(np.max(scanned_pixels_percantages) if scanned_pixels_percantages else 0.0)\n",
    "            visited_pixels_by_episode_percentage.append(np.max(visited_pixels_percantages) if visited_pixels_percantages else 0.0)\n",
    "\n",
    "            if episode > 0 and episode % 5 == 0:\n",
    "                action_freq = action_counts / max(1, action_counts.sum())\n",
    "                action_entropy = -np.sum(action_freq * np.log(action_freq + 1e-10))\n",
    "                target_entropy = np.log(env.action_space.n) * 0.65\n",
    "\n",
    "                if action_entropy < target_entropy and episode < decay_episodes:\n",
    "                    most_used = np.argmax(action_counts)\n",
    "                    second_most = np.argsort(action_counts)[-2]\n",
    "\n",
    "                    # Penalize top 2 most-used actions\n",
    "                    model.b[most_used] *= 0.85\n",
    "                    model.b[second_most] *= 0.92\n",
    "\n",
    "                    # Boost least-used actions\n",
    "                    least_used_indices = np.where(action_freq < 0.02)[0]\n",
    "                    for idx in least_used_indices:\n",
    "                        model.b[idx] *= 1.05\n",
    "\n",
    "                    if episode % 50 == 0:\n",
    "                        print(\n",
    "                            f\"  [Episode {episode}] Entropy={action_entropy:.2f}, most_used={most_used} ({action_freq[most_used] * 100:.1f}%), bias_penalty applied\")\n",
    "\n",
    "            model.epsilon = max(self.epsilon_min, model.epsilon - epsilon_decay_step)\n",
    "\n",
    "            w_change = np.mean(np.abs(model.w - previous_w))\n",
    "            w_changes.append(w_change)\n",
    "            previous_w = model.w.copy()\n",
    "            rewards.append(ep_reward)\n",
    "\n",
    "            if (episode + 1) % log_step == 0:\n",
    "                recent_max = float(np.max(rewards[-log_step:])) if len(rewards) > 0 else float(ep_reward)\n",
    "                print(\n",
    "                    f\"Episode {episode + 1}/{n_episodes}: Max reward for period={recent_max:.2f}, Eps={model.epsilon:.4f}\")\n",
    "\n",
    "        px.line(x=np.arange(1, n_episodes + 1), y=w_changes, labels={'x': 'Episode', 'y': 'Mean |Δw|'},\n",
    "                title='Mean Weight Change over Episodes').show()\n",
    "        px.line(x=np.arange(1, n_episodes + 1), y=rewards, labels={'x': 'Episode', 'y': 'Reward'},\n",
    "                title='Episode Rewards over Time').show()\n",
    "\n",
    "        px.line(x=np.arange(1, n_episodes + 1), y=scanned_pixels_by_episode_percentage, labels={'x': 'Episode', 'y': 'Scanned Pixels Percentage'}, title='Scanned Pixels Percentage over Episodes').show()\n",
    "        px.line(x=np.arange(1, n_episodes + 1), y=visited_pixels_by_episode_percentage, labels={'x': 'Episode', 'y': 'Visited Pixels Percentage'}, title='Visited Pixels Percentage over Episodes').show()\n",
    "\n",
    "        action_freq = action_counts / action_counts.sum()\n",
    "        entropy = -np.sum(action_freq * np.log(action_freq + 1e-10))\n",
    "        print(f'Action distribution during training: {action_counts}')\n",
    "        print(f'Action entropy: {entropy:.3f} (max={np.log(env.action_space.n):.3f})')\n",
    "        print(f'Most used action: {np.argmax(action_counts)} ({action_counts.max() / action_counts.sum() * 100:.1f}%)')\n",
    "        print(f\"Training completed. Max score ever: {np.max(rewards)}\")\n",
    "\n",
    "        model.save(self._file_name_for_class(class_name))\n"
   ],
   "id": "fe4a830dbe66615c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train run",
   "id": "48fd89e46c355484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.888652Z",
     "start_time": "2025-11-27T08:57:33.798291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CLASS_NAME = \"Berzerk\"\n",
    "\n",
    "ale = ALEInterface()\n",
    "gym.register_envs(ale)\n",
    "\n",
    "env = gym.make(\"ALE/Berzerk-v5\", render_mode=\"rgb_array\", frameskip=4)\n",
    "agent = Sarsa(env.action_space.n)\n",
    "observation, info = env.reset()"
   ],
   "id": "7bae41ecb4ae1c5b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.908223Z",
     "start_time": "2025-11-27T08:57:33.898182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "epsilon_min = 0.1\n",
    "\n",
    "trainer = Trainer(epsilon_min=0.05, epsilon_decay_fraction=0.95, initial_epsilon=1.0)\n",
    "agent = trainer.train_if_needed(agent, env, class_name=CLASS_NAME, n_episodes=1000)\n",
    "\n",
    "env.close()"
   ],
   "id": "8140556e3832c90e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for existing model file: sarsa-weights-berzerk.npz\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "8180a1812bf1eb88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:33.929136Z",
     "start_time": "2025-11-27T08:57:33.924123Z"
    }
   },
   "cell_type": "code",
   "source": "agent = Sarsa.load(Trainer._file_name_for_class(CLASS_NAME))",
   "id": "4128d9fb05e18a78",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T08:57:34.583988Z",
     "start_time": "2025-11-27T08:57:33.957726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ale = ALEInterface()\n",
    "gym.register_envs(ale)\n",
    "\n",
    "test_env = gym.make(\"ALE/Berzerk-v5\", render_mode=\"human\", frameskip=4)\n",
    "agent.restrict_exploration()"
   ],
   "id": "80fd0e4d3717b2b3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-27T08:57:34.590170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_episodes = 5\n",
    "total_rewards = []\n",
    "\n",
    "# agent.w = normalize_weights(agent.w)\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    state, _ = test_env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "\n",
    "    actions_count = np.zeros(test_env.action_space.n, dtype=np.int32)\n",
    "    while not done:\n",
    "        feature_state = State(state)\n",
    "        if feature_state.is_empty:\n",
    "            action = 0\n",
    "        else:\n",
    "            action, _ = agent.epsilon_greedy(feature_state.as_vector())\n",
    "        actions_count[action] += 1\n",
    "        next_state, reward, terminated, truncated, _ = test_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        state = next_state\n",
    "        ep_reward += reward\n",
    "\n",
    "    test_env.render()\n",
    "    print(f\"Episode {ep + 1}: Total Reward = {ep_reward}\")\n",
    "    print(f'Action count during round: {actions_count}')\n",
    "    print('---------------------------')\n",
    "    total_rewards.append(ep_reward)\n",
    "\n",
    "test_env.close()\n",
    "\n",
    "print(f\"\\nAverage Test Reward over {n_episodes} episodes: {np.mean(total_rewards):.2f}\")"
   ],
   "id": "55994c398eb234cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
